import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from pprint import pprint 

# TODO: классовая структура

# Представим, что мы переходим только между тремя веб страницами: web_1, web_2 и web_3. Вообще говороя 
# состояния необходимо делать с более сложно структурой: кроме веб страниц, состояния будут 
# отображать мат ожидание и дисперсиюс корости движения мыши, скорости печати и пр. на данной странице, но 
# в данной тестовой версии мы ипользуем в качестве состояний только название веб страницы.  
# Легко понять, что в модели цепей Маркова веб страницы является явными состоянием, 
# то есть таким состояния, о которых в любой момент времени можно точно сказать, 
# находится ли наблюдаемый объект в нем или нет. В противовес явным существуют скрытые,
# но о них будет скзаано позже. Также стоит заметить, что вообще говоря, такая модель цепи Маркова является 
# не полной из-а того, что в ней подрузамивается, что все параметры являются дискртными6 когда на самом деле
# правильнее было бы считать скорости нормально распределенными случайнми величиными6 но это уже следующий этап

states = ['web_1', 'web_2', 'web_3']

# Начальное распрпеделение вероятностей. Сложно интерпретировать начальное распределение в случае
# веб страниц, проще будет пояснить на более живом примере: человек спит с вероятностью 0.35, ест с 
# вероятнстью 0.35 и гуяет с вероятностью 0.3, сложно сказать в каком именно состоянии нахордится человек 
# в момент начала наблюдения, поэтому вводится начальное распределение вероятностей

pi = [0.35, 0.35, 0.3]

# Задаим теперь матрицу переходов между веб страницами - просто матрица вероятностей попасть с web_i на web_j
# понятное дело, что сумма вероятностей перейти из состояния web_i во все остальные состояния равняется единице

q_df = pd.DataFrame(columns=states, index=states)
q_df.loc[states[0]] = [0.4, 0.2, 0.4]
q_df.loc[states[1]] = [0.45, 0.45, 0.1]
q_df.loc[states[2]] = [0.45, 0.25, 0.3]

print(q_df)
print("\n\n")

# create a function that maps transition probability dataframe 
# to markov edges and weights

def _get_markov_edges(df):
    edges = {}
    for col in df.columns:
        for idx in df.index:
            edges[(idx,col)] = df.loc[idx,col]
    return edges

edges_wts = _get_markov_edges(q_df)
pprint(edges_wts)
print("\n\n")

# Теперь займемся скрытыми состояниями цепи. Скрытыми они называются потому, что мы никогда доподлино не знаем,
# в каком именно стостоянии нахоится пользователь, мы можем только рассуждать о наиболее вероятном состоянии соответсвующему
# пройденному пути

hidden_states = ['good', 'bad']

# Легко понять, что начальное распределение лучше выбрать равновероятным

pi = [0.5, 0.5]

# Матрица переходов между скрытыми состояниями

a_df = pd.DataFrame(columns=hidden_states, index=hidden_states)
a_df.loc[hidden_states[0]] = [0.7, 0.3]
a_df.loc[hidden_states[1]] = [0.4, 0.6]

print(a_df, "\n\n")

# Создадим теперь матрицу вероятностей наблюдейний, то есть матрицу в которой записаны вероятности
# Матрица имеет размер (M x Q), где M - число скрытых состояний, а Q - число наблюдений, то есть явных состояний. 
# Важно понимать, что это матрица условных вероятностей.

observable_states = states

b_df = pd.DataFrame(columns=observable_states, index=hidden_states)
b_df.loc[hidden_states[0]] = [0.2, 0.6, 0.2]
b_df.loc[hidden_states[1]] = [0.4, 0.1, 0.5]

print(b_df, "\n\n")

# Созданим из весго имеющегося ребра графа, чтобы было удобнее

hide_edges_wts = _get_markov_edges(a_df)
pprint(hide_edges_wts)
print("\n\n")

emit_edges_wts = _get_markov_edges(b_df)
pprint(emit_edges_wts)
print("\n\n")

# Последовательность наблюдений поведения пользователя закодируем числами

observ_map = {'web_1':0, 'web_2':1, 'web_3':2}
observ = np.array([1,1,2,1,0,1,2,1,0,2,2,0,1,0,1])

# Алгоритм Витерби — алгоритм поиска наиболее подходящего списка состояний (называемого путём Витерби), который в контексте цепей Маркова
# получает наиболее вероятную последовательность произошедших событий. Великолепно написано на https://en.wikipedia.org/wiki/Viterbi_algorithm
# 

def viterbi(pi, A, B, obs):
    
    # A - матрица переходов между сокрытыми состояниями, B - матрица условных вероятностей  
    # получить наблюдение (obs), находясь в сокрытом состоянии s, pi - распределение вероятностей

    # Количество состояний
    K = np.shape(B)[0]
    
    # Число намблюдений
    T = np.shape(obs)[0]
    
    # Инициализируем путь по состояниям нулями
    path = np.zeros(T)

    # T1[i, j] - вероятность наиболее вероятного пути, достигающего вершину i и 
    # генерирующего последовательность obs[: j]
    T1 = np.zeros((K, T))

    # T2[i, j] - хранит в себе элементы x_{j-1} такие, что x_{j} = s_{i} 
    # T2 существует для того, чтобы по T1 потом востановить последовательность
    # скрытых вершин
    T2 = np.zeros((K, T))
    
    # Начальная инициализация
    T1[:, 0] = pi * B[:, obs[0]]
    T2[:, 0] = 0
  
    # Для каждого наблюдения
    for i in range(1, T):
        # Для каждого состояния
        for j in range(K):
            T1[j, i] = np.max(T1[:, i - 1] * A[:, j]) * B[j, obs[i]] 
            T2[j, i] = np.argmax(T1[:, i - 1] * A[:, j] * B[j, obs[i]])
            print('j = {j} and i = {i}: T2[{j}, {i}] = {T2}'.format(j = j, i = i, T2 = T2[j, i]))
    
    # Ищем оптимальный путь
    print('-----------------------------------------------------------------------------------')
    path[T - 1] = np.argmax(T1[:, T - 1])
    for i in range(T - 2, -1, -1):
        path[i] = T2[int(path[i + 1]), i + 1]
        
    return path, T1, T2

a = a_df.values
b = b_df.values

path, T1, T2 = viterbi(pi, a, b, observ)
print('single best state path: \n', path)
print('T1:\n', T1)
print('T2:\n', T2)



