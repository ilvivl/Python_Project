# Zumamotu

## Участники проекта:
* Зубков Максим [github](https://github.com/maximzubkov)
* Турков Матвей [github](https://github.com/turk0v)
* Виноградов Илья [github](https://github.com/ilvivl)

## Описание проекта 
Мы хотим реализовать плагин для браузера, занимающийся анализом поведения пользователя, находящегося за компьютером. Мы будем собирать данные из браузера для как каждой web-страницы, так и для переходов по сайтам в целом, и с некоторым периодом обновлять модель, описывающее поведение пользователя. Модель будет строиться на основании каких-то показательных метрик полученных данных, такие как скорость движения мышки, скорость печатиб вероятность нахождения мыши в некотором конкретной области сайта и прочие. Важной особенностью является то, что мы будем проводить анализ только для тех сайтов, на которых пользователь аутентифицирован.

## Составные части проекта:
#### 0. Проверить предусмотрена ли на сайте аутентификация
#### 1. Создание плагина на google chrome, собирающего данные в формате json о поведении пользователя в сети
#### 2. Сбор данных о переходах пользователя между web-страницами планируется организовать граф переходов
#### 3. Связь сервера с клиентом, посредством python скрипта. Данные полученные в двух предыдущих пунктах будут в формате json отправлены на сервер и сам сервер будет заниматься распределением данных по БД и прочим
#### 4. Хранение полученных данных в БД на сервере
#### 5. Анализ данных поведения, который запускается сразу, как только необходимый объем данных потупил
#### 6. Анализ данных переходов по страницам

## Технологии и языки, используемые в работе

* Python
* JS, HTML, CSS
* PostgreSQL



## Детальное описание проекта
### 0. Проверить предусмотрена ли на сайте аутентификация.
### 1. Google chrome плагинами будет в основном будет заниматься Матвей. Вытаскивание данных из браузера будем при помощи JS. Рассмотрев информацию с данной [страницы](https://developer.mozilla.org/ru/docs/Web/Events), мы выделили несколько ключевых паттернов поведения пользователя(в скобках указано расположение данной информации в терминологии общей для всех расширений в браузерах):
- [x] Координаты, скорость и ускорение мыши (есть RAW данные, нужна обработка)(content_script)
- [x] Скорость печати, горячих клавиши (есть RAW данные, нужна обработка)(content_script)
- [x] Исправления в печати(content_script)
- [x] Навигация по сайту (через кнопки или с помощью колеса мыши)(content_script)
- [x] Размер окна, скорость листания страниц (background)
- [ ] Количество открытых ссылок, количество закладок (background,alarm)
- [ ] Время проводимое на конкретных страницах сайта(content_script)
- [x] Выбросы, то странные привычки, к примеру привычка листать страницу вверх-вниз, когда пользователь ожидает загрузки страницы(? вроде как должны быть выбросами в RAW данных)
- [x] Даблклик на объект(content_script)
- [x] Количество запросов (background) (Можно получить из RAW данных)
- [x] Выделение текста, например, при чтении некоторым людям бывает удобно выделить мышкой тот текст, который им наиболее интересен и время, которое он был выделен(content_script)
### 2. Граф переходов между web-страницами позволяет определить наиболее популярные направления, по которым ходит пользователь, веса ребер графа будут показывать вероятность перехода по ребру, таким образом, можно отследить если вдруг злоумышленник захочет поменять пароль или персональные данные в соц сетях и тому подобное.
### 3. Клиент серверная часть. На сервере будет работать python скрипт, который будет распараллеливать поступления информации. Клиент и сервер будет писать в основном Максим.
### 4. База данных. 
* База данных мы планируем реализовать на сервере и все вычисления соответственно производиться будут на нем же. В базе пока что есть три таблицы:
* * Таблица пользователей "users" с колонками:
* * * id (Primary key)
* * * name
* * Таблица web-страниц "webpage" с колонками:
* * * id (Primary key)
* * * user_id (Foreign key (user_id) references users(id))
* * * model (параметры модели, построенной для данного пользователя и данной страницы)
* * * url
* * Таблица данных "data" с колонками:
* * * id (Primary key)
* * * webpage_id (Foreign key (webpage_id) references webpage(id))
* * * data (это целое множество колонок, они будут определены чуть позже)
* Также на базу будет наложен триггер, который будет срабатывать при появлении достаточного количества новых данных в таблице data. Этот триггер будет запускать python скрипт, подставляющий в модель новые полученные значения и считающий среднюю точность соответствия данные модели, если эта точность окажется ниже некоторого порога, то сервер передает клиенту сообщение о том, что следует запросить у пользователя пароль, подтверждающий личность.  

### 5. Для понимания структуры данных необходимо для начала визуализировать то, что получено от браузера. Кроме обычных методов регрессии и классификации планируется посмотреть на набор координат мыши, как на изображение. Если разбить всю web-страницу на некоторые области, можно подсчитать с какой вероятностью мышка пользователя находится в той или иной части, таким образом данная задача аналогична задаче об анализе изображений, где изображение - массив цветов. 
### 6. Мы будем запоминать пути, пройденные пользователем в течении некоторого периода и, умножая веса каждого из ребер по правилу произведения вероятностей, будем находить общую вероятность пройти по данному пути. Если эта вероятность окажется ниже пороговой, то за компьютером потенциальный злоумышленник.



--------

### Как запустить локально
Пока расширение не появилось в сети для общего пользования и сервер работает только локально.

Чтобы все заработало необходимо :
* Склонировать репозиторий себе на компьютер.
* Установить браузер Google Chrome. 
* Зайти на `chrome:\\extensions` и активировать режим разработчика. 
* Нажать на "Загрузить распакованное расширение" и выбрать папку `chrome_extension` из скачанного репозитрия.

Если все сделано правильно , на данном этапе в верхнем меню должна появиться желтая кошка (временный логотип расширения).

Теперь необходимо запустить сервер,чтобы начать принимать данные. Для этого:
* Перейти в `Python_Project/server_data_tmp`.
* Установить виртуальное окружение (необязательно). 
* Поставить необходимые библиотеки из файла `requirments.txt` либо через команду `pip3 install -r requirments.txt`, либо руками через `pip3 install <name_of_module>`. Возможны проблемы с установкой некоторых библиотек, но для успешной работы необходимо поставить `flask` и `flask_jsonrpc`. 
* Выполнить команду `python3 app/__init__.py`.

Если все сделано правильно, должен запуститься сервер и появиться сообщение содержащее строку `Running on http://127.0.0.1:5000/`. Теперь сервер запущен по указанному адресу, и расширение должно начать отправлять данные в файл `Python_Project/server_data_tmp/app/data_tmp.json`. Теперь достаточно зайти в браузер Google Chrome и продолжить пользоваться им как обычно. Чтобы остановить поступление данных достаточно прервать процесс сервера в терминале. Пока запросы не оптимизированы и едят достаточно много памяти (~0.5 Мб в минуту), поэтому советую пользоваться расширением не более 5-7 минут. 
